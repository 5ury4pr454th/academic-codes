{"cells":[{"cell_type":"markdown","metadata":{"id":"_qiyVDbt_slu"},"source":["## Import Statements"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mD2pejJmWbY4"},"outputs":[],"source":["import struct\n","import cv2 as cv\n","import numpy as np\n","import torch.nn as nn\n","from sklearn.svm import SVC\n","from google.colab import drive\n","from skimage.feature import hog\n","import matplotlib.pyplot as plt\n","from sklearn.cluster import KMeans\n","from skimage.morphology import erosion\n","from torchvision.datasets import MNIST\n","from skimage.transform import rescale, resize\n","from sklearn.metrics import classification_report\n","\n","drive.mount(\"/content/drive\")"]},{"cell_type":"markdown","metadata":{"id":"GZXsR7F6q2YQ"},"source":["## Question 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fGVzPMYqq13Q"},"outputs":[],"source":["# Reading the image\n","img = cv.imread('faces.png')\n","\n","converted_img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n","  \n","# Converting image to grayscale\n","gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n","  \n","# Loading the required haar-cascade xml classifier file (the classifier has already been trained with ADABoost Algorithm )\n","haar_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n","  \n","# Applying the face detection method on the grayscale image\n","faces_rect = haar_cascade.detectMultiScale(gray_img, 1.1, 9)\n","  \n","# Iterating through rectangles of detected faces\n","for (x, y, w, h) in faces_rect:\n","    cv.rectangle(converted_img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n","\n","plt.figure(figsize = (20, 10))\n","plt.imshow(converted_img)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"j_GMTMoBwheX"},"source":["## Question 3"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":234},"executionInfo":{"elapsed":566,"status":"error","timestamp":1649957832468,"user":{"displayName":"Surya Prasath R","userId":"18215364500953637153"},"user_tz":-330},"id":"VNjo0WGXwgpt"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-2-5b46df4b182b\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read the grayscale image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/tounching_grayscale.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# use OTSU thresholding to binarize the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_img\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_OTSU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'cv' is not defined"]}],"source":["# read the grayscale image\n","img = cv.imread(\"/content/tounching_grayscale.png\", cv.IMREAD_GRAYSCALE)\n","\n","# use OTSU thresholding to binarize the image\n","(thresh, binary_img) = cv.threshold(img, 100, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n","\n","# plot the images\n","fig, ax = plt.subplots(1, 2, figsize = (15, 7))\n","ax[0].imshow(img, cmap = \"gray\")\n","ax[0].set_title(\"Original Image\")\n","ax[1].set_title(\"Binary Image\")\n","ax[1].imshow(binary_img, cmap = \"gray\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x92meEggwmzU"},"outputs":[],"source":["# convert the image into a feature map and apply KMeans algorithm to get the cluster centroids \n","\n","X = np.asarray(np.where(binary_img == 255)).T\n","kmeans_model = KMeans(n_clusters = 12, max_iter = 300)\n","kmeans_model.fit(X)\n","\n","plt.figure(figsize = (10, 7))\n","\n","# plot the centroids\n","f1 = np.round(kmeans_model.cluster_centers_.T[1]).astype(np.int16)\n","f2 = np.round(kmeans_model.cluster_centers_.T[0]).astype(np.int16)\n","\n","ax = plt.gca()\n","X_f = np.asarray([f1, f2])\n","plt.scatter(f1, f2)\n","plt.imshow(binary_img, cmap = \"gray\")\n","plt.title(\"Centroids for each cluster found by K-Means\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cO7QmshWwp0b"},"outputs":[],"source":["# set the number iterations for eroding an image\n","erosion_level = 1\n","\n","# define a blank final image\n","final_img = np.zeros_like(binary_img)\n","\n","# add each eroded cluster\n","for i in range(12):\n","\n","  # get the labels for each point, corresponding to each predicted cluster\n","  labels_index = X[np.where(kmeans_model.labels_ == i)[0]]\n","\n","  # define a blank image\n","  blank_image = np.zeros_like(binary_img)\n","  \n","  # plot all the points of each cluster on the blank image\n","  for j in labels_index:\n","    blank_image[j[0], j[1]] = 255\n","  \n","  # erode the blank image to prevent it touching from other clusters\n","  for k in range(erosion_level):\n","    blank_image = erosion(blank_image)\n","  \n","  # add the cluster to the final image\n","  final_img += blank_image\n","\n","# plot both the images\n","fig, ax = plt.subplots(1, 2, figsize = (15, 7))\n","ax[0].imshow(binary_img, cmap = \"gray\")\n","ax[0].set_title(\"Before Clustering and Seperating\")\n","ax[1].set_title(\"After Clustering and Seperating\")\n","ax[1].imshow(final_img, cmap = \"gray\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"GYIDfj8Ewrjl"},"source":["## Question 4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5uHaEJMlws-p"},"outputs":[],"source":["# read the image\n","og_img = cv.imread(\"/content/shapes.png\",cv.IMREAD_GRAYSCALE)\n","# convert the image into a binary image\n","(thresh, binary_img) = cv.threshold(og_img, 100, 1, cv.THRESH_BINARY)\n","# plot the image\n","plt.figure(figsize = (8, 8))\n","plt.imshow(binary_img, cmap = \"gray\")\n","plt.title(\"Original Image\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gnpEJsD3wv2R"},"outputs":[],"source":["# get a copy of the image and draw contours on the copy\n","edged = binary_img.copy()\n","contours, hierarchy = cv.findContours(edged, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n","\n","# plot the required figures\n","nrows = 1\n","ncols = 3\n","\n","fig, ax = plt.subplots(nrows, ncols, figsize = (25, 7))\n","\n","for row in range(nrows):\n","  for col in range(ncols):\n","\n","    contour_no = row*ncols + col\n","    \n","    # fit ellipse\n","    (x,y),(MA,ma),angle = cv.fitEllipse(contours[contour_no])\n","    im = cv.cvtColor(binary_img, cv.COLOR_GRAY2RGB)\n","    \n","    # get the eccentricity\n","    e = np.sqrt(abs((MA/2)**2 - (ma/2)**2))/max(MA/2, ma/2)\n","    \n","    # get the bounding Rectangle\n","    x,y,w,h = cv.boundingRect(contours[contour_no])\n","    \n","    # show all\n","    ax[col].imshow(cv.rectangle(im,(x,y),(x+w,y+h),(0,255,0),1))\n","    ax[col].imshow(binary_img, cmap = \"gray\", alpha = 0.3)\n","    ax[col].set_title(f\"e={np.round(e, 3)}\")\n","    \n","plt.suptitle(\"Bounding Box and Eccentricity(e) for all objects\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"NeHuKcMD6fkp"},"source":["## Question 5\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_TUdJ6u_InQ"},"outputs":[],"source":["c1 = cv.imread(\"d1.png\")\n","c2 = cv.imread(\"d2.png\")\n","\n","c1 = cv.cvtColor(c1, cv.COLOR_BGR2RGB)\n","c2 = cv.cvtColor(c2, cv.COLOR_BGR2RGB)\n","\n","fig, ax = plt.subplots(1, 2, figsize = (20, 10))\n","ax[0].imshow(c1)\n","ax[1].imshow(c2)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"j1Lmon1ZhlPj"},"source":["### Harris Corner Detector"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lwlb4l1jhfbY"},"outputs":[],"source":["# convert to grayscale\n","gray_c1 = cv.cvtColor(c1, cv.COLOR_RGB2GRAY)\n","gray_c2 = cv.cvtColor(c2, cv.COLOR_RGB2GRAY)\n","\n","# detect with Harris corner detector, and dilate for more visibility\n","c1_dst = cv.cornerHarris(gray_c1,2,3,0.1)\n","c1_dst = cv.dilate(c1_dst, None)\n","\n","c2_dst = cv.cornerHarris(gray_c2,2,3,0.1)\n","c2_dst = cv.dilate(c2_dst, None)\n","\n","# create images\n","marker_img_c1 = c1.copy()\n","marker_img_c1[c1_dst \u003e 0.05*np.max(c1_dst)] = [255,0,0]\n","\n","marker_img_c2 = c2.copy()\n","marker_img_c2[c2_dst \u003e 0.05*np.max(c2_dst)] = [255,0,0]\n","\n","fig, ax = plt.subplots(1, 2, figsize = (20, 10))\n","ax[0].imshow(marker_img_c1)\n","ax[1].imshow(marker_img_c2)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"lsuA3QYzhoNy"},"source":["### ORB detector"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lA1sEJXuhq-u"},"outputs":[],"source":["# Initialize the ORB detector algorithm\n","orb = cv.ORB_create()\n","  \n","# detect keypoints and descriptors\n","queryKeypoints, queryDescriptors = orb.detectAndCompute(gray_c2,None)\n","trainKeypoints, trainDescriptors = orb.detectAndCompute(gray_c1,None)\n"," \n","# Initialize the Matcher for matching\n","# the keypoints and then match the\n","# keypoints\n","matcher = cv.BFMatcher()\n","matches = matcher.match(queryDescriptors,trainDescriptors)\n","\n","final_img = cv.drawMatches(c1, queryKeypoints,\n","c2, trainKeypoints, matches[:20],None)\n","  \n","final_img = cv.resize(final_img, (1000,500))\n"," \n","# Show the final image\n","plt.figure(figsize = (20, 10))\n","plt.imshow(final_img)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"oa1GWFVjkHin"},"source":["## Question 6"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dK2a3XA9lKGG"},"outputs":[],"source":["# get the dataset\n","fake_images = []\n","real_images = []\n","\n","for file in os.listdir(\"/kaggle/input/real-and-fake-face-detection/real_and_fake_face/training_fake\"):\n","    filename = r\"../input/real-and-fake-face-detection/real_and_fake_face/training_fake/\" + file\n","    fake_images.append(cv.imread(filename, cv.IMREAD_GRAYSCALE))\n","for file in os.listdir(\"/kaggle/input/real-and-fake-face-detection/real_and_fake_face/training_real\"):\n","    filename = r\"../input/real-and-fake-face-detection/real_and_fake_face/training_real/\" + file\n","    real_images.append(cv.imread(filename, cv.IMREAD_GRAYSCALE))    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m4KPIevClPYX"},"outputs":[],"source":["# get HOG features based on the following parameters\n","def get_hog_features(j):\n","    return hog(resize(j, (128,64)), cells_per_block = (8,8), pixels_per_cell = (8, 8))\n","\n","\n","# iterate over each image and get hog features for each image\n","\n","X = np.asarray(real_images + fake_images)\n","y = np.asarray([1] * len(real_images) + [0] * len(fake_images))\n","\n","train_data, test_data, train_labels, test_labels = train_test_split(X, y, test_size = 0.25, shuffle = True, stratify = y)\n","\n","hog_train_data = []\n","hog_test_data = []\n","\n","for i in range(train_data.shape[0]):\n","    hog_train_data.append(get_hog_features(train_data[i,:,:]))\n","\n","for i in range(test_data.shape[0]):\n","    hog_test_data.append(get_hog_features(test_data[i,:,:]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PTcRWUzRlhs6"},"outputs":[],"source":["# train and test with classifier\n","classifier = SVC(verbose = 2)\n","classifier.fit(hog_train_data,train_labels)\n","\n","print(classification_report(classifier.predict(hog_test_data), test_labels))"]},{"cell_type":"markdown","metadata":{"id":"A1PI_5oLw6FA"},"source":["## Question 7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ZgY1Do70uWu"},"outputs":[],"source":["# this converts idx3-type files to numpy arrays\n","\n","with open('/content/drive/MyDrive/mnist/MNIST/raw/train-images-idx3-ubyte','rb') as f:\n","    magic, size = struct.unpack(\"\u003eII\", f.read(8))\n","    nrows, ncols = struct.unpack(\"\u003eII\", f.read(8))\n","    train_data = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('\u003e'))\n","    train_data = train_data.reshape((size, nrows, ncols))\n","\n","with open('/content/drive/MyDrive/mnist/MNIST/raw/train-labels-idx1-ubyte', 'rb') as i:\n","    magic, size = struct.unpack('\u003eII', i.read(8))\n","    train_labels = np.fromfile(i, dtype=np.dtype(np.uint8)).newbyteorder(\"\u003e\")\n","\n","# ## test images\n","with open('/content/drive/MyDrive/mnist/MNIST/raw/t10k-images-idx3-ubyte','rb') as f1:\n","    magic, size = struct.unpack(\"\u003eII\", f1.read(8))\n","    nrows, ncols = struct.unpack(\"\u003eII\", f1.read(8))\n","    test_data = np.fromfile(f1, dtype=np.dtype(np.uint8).newbyteorder('\u003e'))\n","    test_data = test_data.reshape((size, nrows, ncols))\n","\n","with open('/content/drive/MyDrive/mnist/MNIST/raw/t10k-labels-idx1-ubyte', 'rb') as i:\n","    magic, size = struct.unpack('\u003eII', i.read(8))\n","    test_labels = np.fromfile(i, dtype=np.dtype(np.uint8)).newbyteorder(\"\u003e\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"khwL4RYlXi0h"},"outputs":[],"source":["# get HOG features based on the following parameters\n","def get_hog_features(j):\n","  return hog(j, cells_per_block = (2,2), pixels_per_cell = (8, 8))\n","\n","# iterate over each image and save in numpy array\n","\n","hog_train_data = []\n","hog_test_data = []\n","\n","for i in range(train_data.shape[0]):\n","  hog_train_data.append(get_hog_features(train_data[i,:,:]))\n","\n","for i in range(test_data.shape[0]):\n","  hog_test_data.append(get_hog_features(test_data[i,:,:]))\n","\n","model_train_data = np.asarray(hog_train_data)\n","model_test_data = np.asarray(hog_test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62698,"status":"ok","timestamp":1649413303696,"user":{"displayName":"Surya Prasath R","userId":"18215364500953637153"},"user_tz":-330},"id":"Y8lsquGn57WE","outputId":"5bef7adf-a2ce-4daa-ae97-8a31a358bb18"},"outputs":[{"name":"stdout","output_type":"stream","text":["[LibSVM]              precision    recall  f1-score   support\n","\n","           0       0.97      0.99      0.98       980\n","           1       0.99      0.99      0.99      1135\n","           2       0.97      0.98      0.97      1032\n","           3       0.96      0.97      0.97      1010\n","           4       0.97      0.97      0.97       982\n","           5       0.98      0.97      0.98       892\n","           6       0.98      0.98      0.98       958\n","           7       0.98      0.95      0.97      1028\n","           8       0.96      0.96      0.96       974\n","           9       0.96      0.96      0.96      1009\n","\n","    accuracy                           0.97     10000\n","   macro avg       0.97      0.97      0.97     10000\n","weighted avg       0.97      0.97      0.97     10000\n","\n"]}],"source":["# train a simple SVC classifier and fit the training data\n","classifier = SVC(verbose = 2)\n","classifier.fit(model_train_data,train_labels)\n","\n","# predict from test data and evaluate the results\n","test_labels_predicted = classifier.predict(model_test_data)\n","print(classification_report(test_labels, test_labels_predicted))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNTXNBcMrRZ8hvPpb8NRXlc","collapsed_sections":[],"mount_file_id":"16Vlc4OFO0zyowS1Sj0gl_sNaS1CsJuLH","name":"CV Assignment 2.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}