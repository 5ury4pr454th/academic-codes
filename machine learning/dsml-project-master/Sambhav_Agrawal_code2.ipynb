{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"raw/train.csv\").drop(\"Unnamed: 0\", axis = 1)\n",
    "test_df = pd.read_csv(\"raw/test.csv\")\n",
    "train_labels = pd.read_csv(\"raw/train_class_labels.csv\").drop(\"Unnamed: 0\", axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_df['native-country'] = train_df['native-country'].apply(lambda x: 'Others' if x != 'United-States' else 'United-States')\n",
    "test_df['native-country'] = test_df['native-country'].apply(lambda x: 'Others' if x != 'United-States' else 'United-States')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\"\"\"Classes for transformations\"\"\"\n",
    "\n",
    "class RemoveOutliers(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Removes outliers using IQR method\"\"\"\n",
    "\n",
    "    def __init__(self, columns = []):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, df, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df, y = None):\n",
    "        for col_no, col in enumerate(self.columns):\n",
    "            q1 = df[col].quantile(0.25)\n",
    "            q3 = df[col].quantile(0.75)\n",
    "            iq_range = q3 - q1\n",
    "            df[col] = df[col].clip(lower = q1 - 1.5*iq_range, upper = q3 + 1.5*iq_range)\n",
    "        return df\n",
    "\n",
    "class MajorityImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Removes outliers using IQR method\"\"\"\n",
    "\n",
    "    def __init__(self, columns = []):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, df, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df, y = None):\n",
    "        for i in self.columns:\n",
    "            df[i] = df[i].fillna(df[i].mode())\n",
    "        return df\n",
    "\n",
    "class AddPolyFeatures(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Add Polynomial features\"\"\"\n",
    "\n",
    "    def __init__(self, columns = []):\n",
    "        self.columns = columns\n",
    "        self.rename_dict = dict()\n",
    "\n",
    "    def fit(self, df, y = None):\n",
    "        for i in range(df.shape[1]):\n",
    "            self.rename_dict[i] = \"pf_\" + str(i)\n",
    "        return self\n",
    "\n",
    "    def transform(self, df, y = None):\n",
    "        polynomial_features = PolynomialFeatures()\n",
    "        polynomial_df = polynomial_features.fit_transform(df[self.columns])\n",
    "        polynomial_df = pd.DataFrame(polynomial_df).rename(self.rename_dict)\n",
    "        return pd.merge(left = df, right = polynomial_df, left_index=True, right_index = True)\n",
    "\n",
    "class MinMaxScale(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Normalizing Numerical Variables\"\"\"\n",
    "\n",
    "    def __init__(self,columns=[]):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, df, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df, y = None):\n",
    "        scaler = MinMaxScaler()\n",
    "        df[self.columns] = scaler.fit_transform(df[self.columns])\n",
    "        return df\n",
    "\n",
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"For dropping unnecessary columns\"\"\"\n",
    "\n",
    "    def __init__(self,columns=[]):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, df, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df, y = None):\n",
    "        return df.drop(self.columns, axis = 1)\n",
    "\n",
    "class OneHotEncode(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"For One Hot Encoding categorical variables\"\"\"\n",
    "\n",
    "    def __init__(self,columns=[]):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, df, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,df, y = None):\n",
    "        for i in self.columns:\n",
    "            df[i+'i'] = df[i]\n",
    "        return pd.get_dummies(df, columns = self.columns, drop_first=True)\n",
    "\n",
    "class LabelEncode(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"For Label Encoding Categorical Variables\"\"\"\n",
    "\n",
    "    def __init__(self, columns = []):\n",
    "        self.columns = columns\n",
    "        self.encoders = []\n",
    "\n",
    "    def fit(self, df, y = None):\n",
    "        for i in self.columns:\n",
    "            self.encoders.append(LabelEncoder())\n",
    "        for i,col in enumerate(self.columns):\n",
    "            self.encoders[i].fit(df[col])\n",
    "        return self\n",
    "\n",
    "    def transform(self, df, y = None):\n",
    "        for col_no, i in enumerate(self.columns):\n",
    "            df[i] = self.encoders[col_no].transform(df[i])\n",
    "        return df\n",
    "\n",
    "class AddSmote(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"For Label Encoding Categorical Variables\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.smt = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        self.smt = SMOTETomek()\n",
    "        my_df = self.smt.fit_resample(X, y)\n",
    "        return my_df\n",
    "\n",
    "class Estimate(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, estimator = \"lg\"):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def fit(self, y = None):\n",
    "        return self\n",
    "\n",
    "    def predict(self, df, y = None):\n",
    "        if self.estimator == \"lg\":\n",
    "            lr = LogisticRegression()\n",
    "            lr.fit(df, y)\n",
    "            return lr\n",
    "        elif self.estimator == \"svc\":\n",
    "            svc = SVC()\n",
    "            svc.fit(df, y)\n",
    "            return svc\n",
    "        elif self.estimator == \"dtc\":\n",
    "            dtc = DecisionTreeClassifier()\n",
    "            dtc.fit(df, y)\n",
    "            return dtc\n",
    "        elif self.estimator == \"rf\":\n",
    "            rf = RandomForestClassifier()\n",
    "            rf.fit(df, y)\n",
    "            return rf\n",
    "        elif self.estimator == \"knn\":\n",
    "            knn = KNeighborsClassifier()\n",
    "            knn.fit(df, y)\n",
    "            return knn\n",
    "        elif self.estimator == \"adt\":\n",
    "            adt = AdaBoostClassifier()\n",
    "            adt.fit(df, y)\n",
    "            return adt\n",
    "        else:\n",
    "            return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "X_t, X_v, y_t, y_v = train_test_split(train_df, train_labels['income_>50K'], test_size=0.3)\n",
    "\n",
    "pre_pipeLine = Pipeline([\n",
    "    (\"remove_outliers\", RemoveOutliers(columns = [\"age\", \"fnlwgt\", \"hours-per-week\"])),\n",
    "    (\"imputevalues\", MajorityImputer(columns = [\"occupation\"])),\n",
    "    (\"dropper\", DropColumns(columns=['education'])),\n",
    "                         (\"label_encoder\", LabelEncode(columns=['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country'])),\n",
    "                         (\"minmaxscaler\", MinMaxScale(columns=[\"age\", \"fnlwgt\", \"hours-per-week\", \"capital-gain\", \"capital-loss\"]))])\n",
    "\n",
    "# SMOTE\n",
    "X_t = pre_pipeLine.fit_transform(X = X_t)\n",
    "X_v = pre_pipeLine.fit_transform(X = X_v)\n",
    "smt = SMOTETomek()\n",
    "X_t, y_t = smt.fit_resample(X_t, y_t)\n",
    "smt = SMOTETomek()\n",
    "X_v, y_v = smt.fit_resample(X_v, y_v)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 10)\n",
    "\n",
    "mean_accuracy_scores = []\n",
    "mean_test_accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X_t, y_t):\n",
    "\n",
    "    X_train, X_test = X_t.iloc[train_index], X_t.iloc[test_index]\n",
    "    y_train, y_test = y_t.iloc[train_index], y_t.iloc[test_index]\n",
    "\n",
    "    rfc = RandomForestClassifier(max_depth = 30, min_samples_split=10)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    mean_accuracy_scores.append(roc_auc_score(rfc.predict(X_train), y_train))\n",
    "    mean_test_accuracy_scores.append(roc_auc_score(rfc.predict(X_test), y_test))\n",
    "\n",
    "print(\"Mean KFold Score (Train) = \", np.mean(mean_accuracy_scores))\n",
    "print(\"Mean KFold Score (Test) = \", np.mean(mean_test_accuracy_scores))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(max_depth= 30, min_samples_split=10)\n",
    "random_forest.fit(X_t, y_t)\n",
    "print(classification_report(random_forest.predict(X_v), y_v))\n",
    "print(roc_auc_score(random_forest.predict(X_v), y_v))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tree explainer model\n",
    "import shap\n",
    "explainer = shap.TreeExplainer(random_forest)\n",
    "chosen_instance = X_v.iloc[565:575]\n",
    "shap_values = explainer.shap_values(chosen_instance)\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1], chosen_instance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}